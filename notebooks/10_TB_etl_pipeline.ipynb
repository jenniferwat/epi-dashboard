{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3459c163-3eac-4c42-8bfe-a6830824b752",
   "metadata": {},
   "source": [
    "## Tuberculosis data WHO GHO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52359430-dcae-4bb2-8ecb-1df6dcd9f6b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries (installed in epi-core environment)\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text, URL\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1932f423-e579-47e1-af37-117dad74668f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WHS3_522',\n",
       " 'WHS3_54',\n",
       " 'UHC_TB_DT',\n",
       " 'TB_1',\n",
       " 'TB_c_lab_cul_5m',\n",
       " 'TB_c_new_snep_tsr',\n",
       " 'TB_c_newinc',\n",
       " 'TB_e_inc_num_014',\n",
       " 'TB_c_lab_sm_100k',\n",
       " 'TB_e_inc_tbhiv_100k',\n",
       " 'TB_e_prev_num',\n",
       " 'TB_effective_treatment_coverage',\n",
       " 'TB_tot_newrel',\n",
       " 'TB_e_inc_num',\n",
       " 'TB_e_inc_tbhiv_num',\n",
       " 'TB_e_mort_exc_tbhiv_num',\n",
       " 'MDG_0000000018',\n",
       " 'MDG_0000000020',\n",
       " 'MDG_0000000017',\n",
       " 'MDG_0000000031',\n",
       " 'MDG_0000000022',\n",
       " 'MDG_0000000023',\n",
       " 'MDG_0000000030',\n",
       " 'TB_Notification_agesex_num',\n",
       " 'MDG_0000000024']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a list of Indicator codes from api url\n",
    "url = \"https://ghoapi.azureedge.net/api/Indicator?$filter=contains(IndicatorName,%20%27Tuberculosis%27)\"\n",
    "\n",
    "response = requests.get(url) # fetch api response \n",
    "data = response.json() # json to python dict\n",
    "indicator_codes = [item[\"IndicatorCode\"] for item in data[\"value\"]] #loop through each value and get code b\n",
    "indicator_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a738390b-a3b3-4673-a8fc-2e89bec5b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the data looks like for each by querying each indicator code \n",
    "# loop through list of codes, fetch first record and print out keys (fields)\n",
    "\n",
    "valid_indicator_codes = []  \n",
    "\n",
    "for code in indicator_codes:\n",
    "    url = f\"{base_url}{code}\"\n",
    "    resp = requests.get(url)\n",
    "    indicator_data = resp.json()\n",
    "\n",
    "    if \"value\" in indicator_data and len(indicator_data[\"value\"]) > 0:\n",
    "        first_record = indicator_data[\"value\"][0]\n",
    "        # fields = list(first_record.keys())\n",
    "        # print(f\"Indicator: {code}\")\n",
    "        # print(f\"first record: {first_record}\\n\")\n",
    "        valid_indicator_codes.append(code)  # keep only if data exists\n",
    "    # else:\n",
    "        # print(f\"Indicator: {code} (No data returned)n\")\n",
    "\n",
    "# replace indicator codes\n",
    "indicator_codes = valid_indicator_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33e0d2d6-9f47-492a-b3f7-47f15dc4c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for .env\n",
    "\n",
    "env_path = Path.cwd().parent / \"env\" / \".env\"  # up one folder\n",
    "\n",
    "if not os.path.exists(env_path):\n",
    "    sys.exit(f\"Missing {env_path} file. Please create one with your DB credentials.\")\n",
    "\n",
    "load_dotenv(dotenv_path=env_path) \n",
    "\n",
    "PG_USER = os.getenv(\"PGUSER\")\n",
    "PG_PASSWORD = os.getenv(\"PGPASSWORD\")\n",
    "PG_HOST = os.getenv(\"PGHOST\")\n",
    "PG_PORT = os.getenv(\"PGPORT\")\n",
    "PG_DATABASE = os.getenv(\"PGDATABASE\")\n",
    "\n",
    "# Validate\n",
    "missing_vars = [var for var, val in {\n",
    "    \"PG_USER\": PG_USER,\n",
    "    \"PG_PASSWORD\": PG_PASSWORD,\n",
    "    \"PG_HOST\": PG_HOST,\n",
    "    \"PG_PORT\": PG_PORT,\n",
    "    \"PG_DATABASE\": PG_DATABASE\n",
    "}.items() if val is None]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"Missing required environment variables: {', '.join(missing_vars)} \"\n",
    "             f\"\\nMake sure they are defined in {env_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e0fed65-c7c4-4088-a99c-f00e4c6338cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "\n",
    "pg_url = URL.create(\n",
    "    \"postgresql+psycopg\",\n",
    "    username=os.getenv(\"PGUSER\"),\n",
    "    password=os.getenv(\"PGPASSWORD\"),\n",
    "    host=os.getenv(\"PGHOST\", \"localhost\"),\n",
    "    port=int(os.getenv(\"PGPORT\", 5432)),\n",
    "    database=os.getenv(\"PGDATABASE\"),\n",
    ")\n",
    "\n",
    "INDICATORS = indicator_codes\n",
    "BASE_URL = \"https://ghoapi.azureedge.net/api\"  # WHO GHO OData endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4bbbfa1-9f9b-47cd-9fd9-5b78e596bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to db\n",
    "engine = create_engine(pg_url, pool_pre_ping=True)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # Drop existing tables if you want a clean run\n",
    "    conn.execute(text(\"\"\"\n",
    "    DO $$ DECLARE r RECORD;\n",
    "    BEGIN\n",
    "        FOR r IN (SELECT tablename FROM pg_tables WHERE schemaname = 'public') LOOP\n",
    "            EXECUTE 'DROP TABLE IF EXISTS public.' || quote_ident(r.tablename) || ' CASCADE';\n",
    "        END LOOP;\n",
    "    END $$;\n",
    "    \"\"\"))\n",
    "    conn.commit()\n",
    "\n",
    "# cur = psycopg2.connect(pg_url).cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0d2688d-fcc9-47a7-a2b7-ecc29cfc63fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema created/verified.\n"
     ]
    }
   ],
   "source": [
    "# create schema by running sql file\n",
    "\n",
    "def run_sql_file(engine, path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"SQL file not found: {path}\")\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sql_text = f.read()\n",
    "    # exec_driver_sql allows multiple statements separated by semicolons\n",
    "    with engine.begin() as conn:      # begins a transaction\n",
    "        conn.exec_driver_sql(sql_text)\n",
    "\n",
    "\n",
    "try:\n",
    "    run_sql_file(engine, os.path.join(\"..\", \"src\\db\", \"schema.sql\") if os.path.basename(os.getcwd())==\"notebooks\" else \"scripts/schema.sql\")\n",
    "    print(\"Schema created/verified.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to apply SQL files:\", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52660da-b5e2-4f4c-908f-004b08e36e15",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3686d6d3-8878-45ff-b391-b19b70fd7a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, re\n",
    "from datetime import date\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "213439ea-f9dd-4aa7-879e-f6a02cbdcde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate a range of years (backfill) one time fix\n",
    "\n",
    "# with engine.begin() as conn:\n",
    "#     conn.execute(text(\"\"\"\n",
    "#     INSERT INTO dim_time (year, start_date, end_date)\n",
    "#     SELECT gs, make_date(gs,1,1), make_date(gs,12,31)\n",
    "#     FROM generate_series(1950, 2050) AS gs\n",
    "#     ON CONFLICT (year) DO NOTHING;\n",
    "#     \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6370aabc-8d2f-4501-93c2-048ad6bd319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract functions\n",
    "\n",
    "def get_json(url, retries=3):\n",
    "    for i in range(retries):\n",
    "        r = requests.get(url, timeout=60)\n",
    "        if r.ok:\n",
    "            return r.json()\n",
    "        time.sleep(1 + i)\n",
    "    r.raise_for_status()\n",
    "\n",
    "def pick_dim(rec, target_type):\n",
    "    # Finds the first Dim{1..3} whose type matches target_type\n",
    "    for i in (\"1\",\"2\",\"3\"):\n",
    "        if rec.get(f\"Dim{i}Type\") == target_type:\n",
    "            return rec.get(f\"Dim{i}\")\n",
    "    return None\n",
    "\n",
    "def sex_label_from_code(code):\n",
    "    if not code: return None\n",
    "    mapping = {\n",
    "        \"SEX_FMLE\": \"Female\",\n",
    "        \"SEX_FEMALE\": \"Female\",\n",
    "        \"SEX_MALE\": \"Male\",\n",
    "        \"SEX_MLE\": \"Male\",\n",
    "        \"SEX_BTSX\": \"Both sexes\",\n",
    "        \"SEX_UNKNOWN\": \"Unknown\"\n",
    "    }\n",
    "    return mapping.get(code, code)\n",
    "\n",
    "def agegroup_label_from_code(code):\n",
    "    if not code: return None\n",
    "    unit = \"years\" if \"YEARS\" in code else (\"months\" if \"MONTHS\" in code else \"\")\n",
    "    if code.startswith(\"AGEGROUP_\"):\n",
    "        raw = code[len(\"AGEGROUP_\"):]\n",
    "        # Normalize common forms like YEARS15-24 -> \"15–24 years\"\n",
    "        digits = re.findall(r\"\\d+\", raw)\n",
    "        if len(digits) == 2 and \"-\" in raw:\n",
    "            label = f\"{digits[0]}–{digits[1]} {unit}\".strip()\n",
    "            return label\n",
    "        if len(digits) == 1 and (\"PLUS\" in raw or \"MORE\" in raw or raw.endswith(\"+\")):\n",
    "            label = f\"{digits[0]}+ {unit}\".strip()\n",
    "            return label\n",
    "        if raw in (\"ALL\", \"YEARSALL\", \"MONTHSALL\"):\n",
    "            return \"All ages\"\n",
    "        # generic fallback\n",
    "        return raw.replace(\"_\", \" \").replace(\"-\", \"–\").replace(\"YEARS\", \"\").replace(\"MONTHS\",\"\").strip() + (f\" {unit}\" if unit else \"\")\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2fc00398-e1c0-4673-ad73-c3ec5a539aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql\n",
    "\n",
    "insert_time_sql = text(\"\"\"\n",
    "INSERT INTO dim_time (year, start_date, end_date)\n",
    "VALUES (:y, make_date(:y,1,1), make_date(:y,12,31))\n",
    "ON CONFLICT (year) DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "upsert_indicator_sql = text(\"\"\"\n",
    "INSERT INTO dim_indicator (indicator_code, indicator_name, language, source_url)\n",
    "VALUES (:indicator_code, :indicator_name, :language, :source_url)\n",
    "ON CONFLICT (indicator_code) DO UPDATE\n",
    "  SET indicator_name = EXCLUDED.indicator_name,\n",
    "      language = EXCLUDED.language,\n",
    "      source_url = EXCLUDED.source_url;\n",
    "\"\"\")\n",
    "\n",
    "upsert_location_sql = text(\"\"\"\n",
    "INSERT INTO dim_location (spatial_dim, location_type, region_code, region_name)\n",
    "VALUES (:spatial_dim, :location_type, :region_code, :region_name)\n",
    "ON CONFLICT (spatial_dim) DO UPDATE\n",
    "  SET location_type = EXCLUDED.location_type,\n",
    "      region_code = EXCLUDED.region_code,\n",
    "      region_name = EXCLUDED.region_name;\n",
    "\"\"\")\n",
    "\n",
    "upsert_sex_sql = text(\"\"\"\n",
    "INSERT INTO dim_sex (sex_code, sex_label)\n",
    "VALUES (:sex_code, :sex_label)\n",
    "ON CONFLICT (sex_code) DO UPDATE\n",
    "  SET sex_label = EXCLUDED.sex_label;\n",
    "\"\"\")\n",
    "\n",
    "upsert_age_sql = text(\"\"\"\n",
    "INSERT INTO dim_agegroup (agegroup_code, agegroup_label)\n",
    "VALUES (:agegroup_code, :agegroup_label)\n",
    "ON CONFLICT (agegroup_code) DO UPDATE\n",
    "  SET agegroup_label = EXCLUDED.agegroup_label;\n",
    "\"\"\")\n",
    "\n",
    "upsert_fact_sql = text(\"\"\"\n",
    "INSERT INTO fact_gho_observation\n",
    "(id, indicator_code, spatial_dim, time_year,\n",
    " sex_code, agegroup_code,\n",
    " value_raw, numeric_value, low, high, comments,\n",
    " data_source_dim_type, data_source_dim,\n",
    " api_record_date, time_dim_type, time_dimension_value, time_begin, time_end)\n",
    "VALUES\n",
    "(:Id, :IndicatorCode, :SpatialDim, :TimeDim,\n",
    " :sex_code, :agegroup_code,\n",
    " :Value, :NumericValue, :Low, :High, :Comments,\n",
    " :DataSourceDimType, :DataSourceDim,\n",
    " :Date, :TimeDimType, :TimeDimensionValue, :TimeDimensionBegin, :TimeDimensionEnd)\n",
    "ON CONFLICT (id) DO UPDATE SET\n",
    "  value_raw = EXCLUDED.value_raw,\n",
    "  numeric_value = EXCLUDED.numeric_value,\n",
    "  low = EXCLUDED.low,\n",
    "  high = EXCLUDED.high,\n",
    "  comments = EXCLUDED.comments,\n",
    "  api_record_date = EXCLUDED.api_record_date;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7d17b72-e5f4-4a4c-87c1-1b20a0f96168",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_time_sql = text(\"\"\"\n",
    "INSERT INTO dim_time (year, start_date, end_date)\n",
    "VALUES (:y, make_date(:y,1,1), make_date(:y,12,31))\n",
    "ON CONFLICT (year) DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "def ensure_time_years(conn, years):\n",
    "    yrs = sorted({y for y in years if isinstance(y, int)})\n",
    "    if not yrs:\n",
    "        return\n",
    "    conn.execute(insert_time_sql, [{\"y\": y} for y in yrs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce1cc2b3-9607-431f-830d-7b9db3272e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with engine\n",
    "\n",
    "# # Upsert dim_indicator metadata ONLY for valid codes\n",
    "# indicator_meta_rows = []\n",
    "# for code in indicator_codes:\n",
    "#     meta = get_json(base_url + f\"Indicator?$filter=IndicatorCode%20eq%20%27{code}%27\").get(\"value\", [])\n",
    "#     if meta:\n",
    "#         m = meta[0]\n",
    "#         indicator_meta_rows.append({\n",
    "#             \"indicator_code\": m[\"IndicatorCode\"],\n",
    "#             \"indicator_name\": m.get(\"IndicatorName\"),\n",
    "#             \"language\": m.get(\"Language\"),\n",
    "#             \"source_url\": base_url + m[\"IndicatorCode\"]\n",
    "#         })\n",
    "#     else:\n",
    "#         # Fallback if metadata not returned: store code as name\n",
    "#         indicator_meta_rows.append({\n",
    "#             \"indicator_code\": code,\n",
    "#             \"indicator_name\": code,\n",
    "#             \"language\": None,\n",
    "#             \"source_url\": base_url + code\n",
    "#         })\n",
    "\n",
    "# with engine.begin() as conn:\n",
    "#     if indicator_meta_rows:\n",
    "#         conn.execute(upsert_indicator_sql, indicator_meta_rows)\n",
    "\n",
    "#     # For each valid indicator, fetch observations and upsert facts (and related dims)\n",
    "#     for code in indicator_codes:\n",
    "#         obs = get_json(base_url + code).get(\"value\", [])\n",
    "#         if not obs:\n",
    "#             continue\n",
    "\n",
    "#         # Upsert locations from this batch (countries & regions)\n",
    "#         loc_rows = {}\n",
    "#         for d in obs:\n",
    "#             sd = d.get(\"SpatialDim\")\n",
    "#             if not sd:\n",
    "#                 continue\n",
    "#             loc_rows[sd] = {\n",
    "#                 \"spatial_dim\": sd,\n",
    "#                 \"location_type\": d.get(\"SpatialDimType\"),\n",
    "#                 \"region_code\": d.get(\"ParentLocationCode\"),\n",
    "#                 \"region_name\": d.get(\"ParentLocation\")\n",
    "#             }\n",
    "#         if loc_rows:\n",
    "#             conn.execute(upsert_location_sql, list(loc_rows.values()))\n",
    "\n",
    "#         # Prepare/normalize rows (year, sex, agegroup) and collect dim members\n",
    "#         sex_rows, age_rows = {}, {}\n",
    "#         obs_rows = []\n",
    "#         for d in obs:\n",
    "#             # Normalize year to int\n",
    "#             if isinstance(d.get(\"TimeDim\"), str):\n",
    "#                 try:\n",
    "#                     d[\"TimeDim\"] = int(d[\"TimeDim\"])\n",
    "#                 except:\n",
    "#                     d[\"TimeDim\"] = None\n",
    "\n",
    "#             # Extract Sex / AgeGroup from any Dim1..Dim3\n",
    "#             sx = pick_dim(d, \"SEX\")\n",
    "#             ag = pick_dim(d, \"AGEGROUP\")\n",
    "#             d[\"sex_code\"] = sx\n",
    "#             d[\"agegroup_code\"] = ag\n",
    "\n",
    "#             if sx and sx not in sex_rows:\n",
    "#                 sex_rows[sx] = {\"sex_code\": sx, \"sex_label\": sex_label_from_code(sx)}\n",
    "#             if ag and ag not in age_rows:\n",
    "#                 age_rows[ag] = {\"agegroup_code\": ag, \"agegroup_label\": agegroup_label_from_code(ag)}\n",
    "\n",
    "#             obs_rows.append(d)\n",
    "\n",
    "#         if sex_rows:\n",
    "#             conn.execute(upsert_sex_sql, list(sex_rows.values()))\n",
    "#         if age_rows:\n",
    "#             conn.execute(upsert_age_sql, list(age_rows.values()))\n",
    "\n",
    "#         if obs_rows:\n",
    "#             conn.execute(upsert_fact_sql, obs_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280c710-2520-44bf-a5a3-73b8b07469e9",
   "metadata": {},
   "source": [
    "### Transform and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4dbc7c7f-cb09-4794-8840-9bf6e7cf947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with engine load\n",
    "\n",
    "# Upsert dim_indicator metadata ONLY for valid codes\n",
    "indicator_meta_rows = []\n",
    "for code in indicator_codes:\n",
    "    meta = get_json(base_url + f\"Indicator?$filter=IndicatorCode%20eq%20%27{code}%27\").get(\"value\", [])\n",
    "    if meta:\n",
    "        m = meta[0]\n",
    "        indicator_meta_rows.append({\n",
    "            \"indicator_code\": m[\"IndicatorCode\"],\n",
    "            \"indicator_name\": m.get(\"IndicatorName\"),\n",
    "            \"language\": m.get(\"Language\"),\n",
    "            \"source_url\": base_url + m[\"IndicatorCode\"]\n",
    "        })\n",
    "    else:\n",
    "        # Fallback if metadata not returned: store code as name\n",
    "        indicator_meta_rows.append({\n",
    "            \"indicator_code\": code,\n",
    "            \"indicator_name\": code,\n",
    "            \"language\": None,\n",
    "            \"source_url\": base_url + code\n",
    "        })\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    if indicator_meta_rows:\n",
    "        conn.execute(upsert_indicator_sql, indicator_meta_rows)\n",
    "\n",
    "    # For each valid indicator, fetch observations and upsert facts (and related dims)\n",
    "    for code in indicator_codes:\n",
    "        obs = get_json(base_url + code).get(\"value\", [])\n",
    "        if not obs:\n",
    "            continue\n",
    "\n",
    "        # Upsert locations from this batch (countries & regions)\n",
    "        loc_rows = {}\n",
    "        for d in obs:\n",
    "            sd = d.get(\"SpatialDim\")\n",
    "            if not sd:\n",
    "                continue\n",
    "            loc_rows[sd] = {\n",
    "                \"spatial_dim\": sd,\n",
    "                \"location_type\": d.get(\"SpatialDimType\"),\n",
    "                \"region_code\": d.get(\"ParentLocationCode\"),\n",
    "                \"region_name\": d.get(\"ParentLocation\")\n",
    "            }\n",
    "        if loc_rows:\n",
    "            conn.execute(upsert_location_sql, list(loc_rows.values()))\n",
    "\n",
    "        # Normalize year and collect years needed\n",
    "        years_needed = []\n",
    "        obs_rows = []\n",
    "        sex_rows, age_rows = {}, {}\n",
    "        \n",
    "        for d in obs:\n",
    "            # Normalize TimeDim -> int (NULL if unparsable)\n",
    "            if isinstance(d.get(\"TimeDim\"), str):\n",
    "                try:\n",
    "                    d[\"TimeDim\"] = int(d[\"TimeDim\"])\n",
    "                except:\n",
    "                    d[\"TimeDim\"] = None\n",
    "        \n",
    "            # Skip rows that have no year to avoid NOT NULL/ FK issues\n",
    "            if d.get(\"TimeDim\") is None:\n",
    "                continue\n",
    "            years_needed.append(d[\"TimeDim\"])\n",
    "        \n",
    "            # Extract Sex / Age group\n",
    "            sx = pick_dim(d, \"SEX\")\n",
    "            ag = pick_dim(d, \"AGEGROUP\")\n",
    "            d[\"sex_code\"] = sx\n",
    "            d[\"agegroup_code\"] = ag\n",
    "        \n",
    "            if sx and sx not in sex_rows:\n",
    "                sex_rows[sx] = {\"sex_code\": sx, \"sex_label\": sex_label_from_code(sx)}\n",
    "            if ag and ag not in age_rows:\n",
    "                age_rows[ag] = {\"agegroup_code\": ag, \"agegroup_label\": agegroup_label_from_code(ag)}\n",
    "        \n",
    "            obs_rows.append(d)\n",
    "        \n",
    "        # Ensure dim_time has all required years BEFORE fact insert\n",
    "        ensure_time_years(conn, years_needed)\n",
    "        \n",
    "        # Upsert sex/age dims then facts\n",
    "        if sex_rows:\n",
    "            conn.execute(upsert_sex_sql, list(sex_rows.values()))\n",
    "        if age_rows:\n",
    "            conn.execute(upsert_age_sql, list(age_rows.values()))\n",
    "        if obs_rows:\n",
    "            conn.execute(upsert_fact_sql, obs_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "101e93cc-0efb-46ca-92e1-395e94a46abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 present? True\n"
     ]
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "    r = conn.execute(text(\"SELECT 1 FROM dim_time WHERE year = 2018\")).fetchone()\n",
    "    print(\"2018 present?\" , bool(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d6374-3c48-46cd-b968-6fcbafb729ed",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "If you ran only part of the script (skipping the dim_time seed), or ran the fact load before seeding dim_time, the FK will fail.\n",
    "\n",
    "Some records have string years; the code above converts them to int and skips records with missing years (otherwise you’d hit NOT NULL on time_year)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (epi-core)",
   "language": "python",
   "name": "epi-core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
