{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3459c163-3eac-4c42-8bfe-a6830824b752",
   "metadata": {},
   "source": [
    "## WHO GHO indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52359430-dcae-4bb2-8ecb-1df6dcd9f6b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries (installed in epi-core environment)\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text, URL\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33e0d2d6-9f47-492a-b3f7-47f15dc4c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for .env\n",
    "\n",
    "env_path = Path.cwd().parent / \"env\" / \".env\"  # up one folder\n",
    "\n",
    "if not os.path.exists(env_path):\n",
    "    sys.exit(f\"Missing {env_path} file. Please create one with your DB credentials.\")\n",
    "\n",
    "load_dotenv(dotenv_path=env_path) \n",
    "\n",
    "PG_USER = os.getenv(\"PGUSER\")\n",
    "PG_PASSWORD = os.getenv(\"PGPASSWORD\")\n",
    "PG_HOST = os.getenv(\"PGHOST\")\n",
    "PG_PORT = os.getenv(\"PGPORT\")\n",
    "PG_DATABASE = os.getenv(\"PGDATABASE\")\n",
    "\n",
    "# Validate\n",
    "missing_vars = [var for var, val in {\n",
    "    \"PG_USER\": PG_USER,\n",
    "    \"PG_PASSWORD\": PG_PASSWORD,\n",
    "    \"PG_HOST\": PG_HOST,\n",
    "    \"PG_PORT\": PG_PORT,\n",
    "    \"PG_DATABASE\": PG_DATABASE\n",
    "}.items() if val is None]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"Missing required environment variables: {', '.join(missing_vars)} \"\n",
    "             f\"\\nMake sure they are defined in {env_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdfa7c0-30b3-478d-bbae-bec18e2123ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e0fed65-c7c4-4088-a99c-f00e4c6338cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "\n",
    "pg_url = URL.create(\n",
    "    \"postgresql+psycopg\",\n",
    "    username=os.getenv(\"PGUSER\"),\n",
    "    password=os.getenv(\"PGPASSWORD\"),\n",
    "    host=os.getenv(\"PGHOST\", \"localhost\"),\n",
    "    port=int(os.getenv(\"PGPORT\", 5432)),\n",
    "    database=os.getenv(\"PGDATABASE\"),\n",
    ")\n",
    "\n",
    "INDICATORS = [\"WHOSIS_000001\", \"WHOSIS_000002\", \"MDG_0000000026\", \"u5mr\", \"MDG_0000000020\"]\n",
    "BASE_URL = \"https://ghoapi.azureedge.net/api\"  # WHO GHO OData endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4bbbfa1-9f9b-47cd-9fd9-5b78e596bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to db\n",
    "engine = create_engine(pg_url, pool_pre_ping=True)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # Drop existing tables if you want a clean run\n",
    "    conn.execute(text(\"\"\"\n",
    "    DO $$ DECLARE r RECORD;\n",
    "    BEGIN\n",
    "        FOR r IN (SELECT tablename FROM pg_tables WHERE schemaname = 'public') LOOP\n",
    "            EXECUTE 'DROP TABLE IF EXISTS public.' || quote_ident(r.tablename) || ' CASCADE';\n",
    "        END LOOP;\n",
    "    END $$;\n",
    "    \"\"\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0d2688d-fcc9-47a7-a2b7-ecc29cfc63fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema created/verified.\n"
     ]
    }
   ],
   "source": [
    "# create schema by running sql file\n",
    "\n",
    "def run_sql_file(engine, path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"SQL file not found: {path}\")\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sql_text = f.read()\n",
    "    # exec_driver_sql allows multiple statements separated by semicolons\n",
    "    with engine.begin() as conn:      # begins a transaction\n",
    "        conn.exec_driver_sql(sql_text)\n",
    "\n",
    "\n",
    "try:\n",
    "    run_sql_file(engine, os.path.join(\"..\", \"scripts\", \"schema.sql\") if os.path.basename(os.getcwd())==\"notebooks\" else \"scripts/schema.sql\")\n",
    "    print(\"Schema created/verified.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to apply SQL files:\", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "926ee961-afea-425a-8009-e61ce38e6abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching WHOSIS_000001...\n",
      "Fetching WHOSIS_000002...\n",
      "Fetching MDG_0000000026...\n",
      "Fetching u5mr...\n",
      "Fetching MDG_0000000020...\n"
     ]
    }
   ],
   "source": [
    "# extract\n",
    "\n",
    "all_records = []\n",
    "\n",
    "for ind in INDICATORS:\n",
    "    print(f\"Fetching {ind}...\")\n",
    "    url = f\"{BASE_URL}/{ind}\"\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Failed to fetch {ind}: {resp.status_code}\")\n",
    "        continue\n",
    "    data = resp.json().get(\"value\", [])\n",
    "    for row in data:\n",
    "        all_records.append({\n",
    "            \"indicator_id\": ind,\n",
    "            \"indicator_name\": row.get(\"IndicatorName\"),\n",
    "            \"country_code\": row.get(\"SpatialDim\"),\n",
    "            \"country_name\": row.get(\"SpatialDimType\"),  # WHO uses this as country name for some datasets\n",
    "            \"region\": row.get(\"ParentLocation\"),\n",
    "            \"year\": int(row.get(\"TimeDim\")) if row.get(\"TimeDim\") else None,\n",
    "            \"value\": float(row.get(\"NumericValue\")) if row.get(\"NumericValue\") else None\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5ae46c6-126a-4d7f-bd06-2637cad4d800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "\n",
    "# Clean up country_name (SpatialDimType is often 'COUNTRY', so we'll fetch proper country names from WHO \"Dimension\" endpoint)\n",
    "# For now, we'll just map code -> itself as placeholder\n",
    "df['country_name'] = df['country_code']\n",
    "\n",
    "# Split into dimension + fact tables\n",
    "dim_indicator = df[['indicator_id', 'indicator_name']].drop_duplicates()\n",
    "dim_country = df[['country_code', 'country_name', 'region']].drop_duplicates()\n",
    "fact_measure = df[['indicator_id', 'country_code', 'year', 'value']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb5de4a0-91ba-46e7-af55-6bf251b52f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL complete. Data loaded into epidemiology database.\n",
      "Indicators loaded: 5 | Countries: 209 | Records: 53601\n"
     ]
    }
   ],
   "source": [
    "# load\n",
    "dim_indicator.to_sql('dim_indicator', engine, if_exists='append', index=False)\n",
    "dim_country.to_sql('dim_country', engine, if_exists='append', index=False)\n",
    "fact_measure.to_sql('fact_measure', engine, if_exists='append', index=False)\n",
    "\n",
    "print(\"ETL complete. Data loaded into epidemiology database.\")\n",
    "print(f\"Indicators loaded: {len(dim_indicator)} | Countries: {len(dim_country)} | Records: {len(fact_measure)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0fd0b-91e0-4f7d-b10c-00a5156949eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (epi-core)",
   "language": "python",
   "name": "epi-core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
